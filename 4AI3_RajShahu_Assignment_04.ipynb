{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajkumarshahu/AI-Colab/blob/main/4AI3_RajShahu_Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc6b82a",
      "metadata": {
        "id": "9bc6b82a"
      },
      "source": [
        "# **<center>Assignment #4 <br>SFWRTECH 4AI3:Artificial Intelligence**\n",
        "**<center>|| <br> ||<br> ||**\n",
        "**<center>Submitted by: Raj Kumar Shahu (ID: 400426052) <br> Date: November 7, 2023<br>**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "ZqrVV3IfnulK"
      },
      "id": "ZqrVV3IfnulK",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "65bcf022",
      "metadata": {
        "id": "65bcf022"
      },
      "source": [
        "#### <b>Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Add a part to the program so that age, gender and ticket class (Pclass) are considered as the input variables (features) for classifying survivors. Construct the logistic regression model and estimate the parameters of the log odd function using the first 200 data points. Print the parameters of the model."
      ],
      "metadata": {
        "id": "gxSTi9AgoJoc"
      },
      "id": "gxSTi9AgoJoc"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e3af450b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3af450b",
        "outputId": "513ee463-a4c3-45de-ecab-e4a003112a41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.03124805, -2.56189611, -0.73096765]]), array([3.24456448]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Convert 'Sex' column to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "dataset['Sex'] = label_encoder.fit_transform(dataset['Sex'])\n",
        "\n",
        "# Extract features and target variable\n",
        "X = dataset[['Age', 'Sex', 'Pclass']].iloc[:200].fillna(0)\n",
        "y = dataset['Survived'].iloc[:200]\n",
        "\n",
        "# Create and fit the logistic regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X, y)\n",
        "\n",
        "log_reg.coef_, log_reg.intercept_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "796d6b02",
      "metadata": {
        "id": "796d6b02"
      },
      "source": [
        "#### <b>Log Loss Calculation for Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Calculate the value of the log-loss function in this case for the sample points 201 to 240 (average of the penalty for these 40 samples) for this model."
      ],
      "metadata": {
        "id": "7R9Gs-R6oVlr"
      },
      "id": "7R9Gs-R6oVlr"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "11c0516a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11c0516a",
        "outputId": "b26cc5e5-5f04-459a-f75d-9462049a9343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5258953496298913\n"
          ]
        }
      ],
      "source": [
        "# Extract features and target variable for samples 201 to 240\n",
        "X_test = dataset[['Age', 'Sex', 'Pclass']].iloc[200:240].fillna(0)\n",
        "y_test = dataset['Survived'].iloc[200:240]\n",
        "\n",
        "# Predict probabilities for the logistic regression model\n",
        "y_pred_proba = log_reg.predict_proba(X_test)\n",
        "\n",
        "# Calculate log loss\n",
        "log_loss_lr = log_loss(y_test, y_pred_proba)\n",
        "print(log_loss_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5fe4470",
      "metadata": {
        "id": "b5fe4470"
      },
      "source": [
        "#### <b>MLP Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Add one more part to the program so that the same classification is done using an MLP neural networks. Assume two hidden layers in the MLP. In each layer, the number of the neurons are 2+n, where n is the right two most digits in your MacID card. This means, for instance if your MacID card is, say, 412345648, then the first hidden layer has 4+2=6 and the second hidden layer has 8+2=10 neurons. Check both relu and sigmoid activation functions and use the one with the best accuracy (less loss) for your final network."
      ],
      "metadata": {
        "id": "v2kL84c9oeFN"
      },
      "id": "v2kL84c9oeFN"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "71967359",
      "metadata": {
        "id": "71967359"
      },
      "outputs": [],
      "source": [
        "# Define and train MLP with sigmoid activation\n",
        "\n",
        "# The architecture of the MLP neural network is determined by the last two digits of the ID \"400426052\", which are \"52\":\n",
        "# - First hidden layer: 5 + 2 = 7 neurons\n",
        "# - Second hidden layer: 2 + 2 = 4 neurons\n",
        "mlp_sigmoid = MLPClassifier(hidden_layer_sizes=(7, 4), activation='logistic', max_iter=1000, random_state=42)\n",
        "mlp_sigmoid.fit(X, y)\n",
        "\n",
        "# Predict probabilities for the model\n",
        "y_pred_proba_sigmoid = mlp_sigmoid.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Log Loss Calculation for NN Model"
      ],
      "metadata": {
        "id": "VEGGOsLeou6X"
      },
      "id": "VEGGOsLeou6X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Calculate and print the value of the loss function for the NN model."
      ],
      "metadata": {
        "id": "sPfnzINDovno"
      },
      "id": "sPfnzINDovno"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate log loss\n",
        "log_loss_mlp  = log_loss(y_test, y_pred_proba_sigmoid)\n",
        "print(log_loss_mlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z5r5UpUnL40",
        "outputId": "ffbe8531-4902-4d6e-943e-3b5aa8b12345"
      },
      "id": "7Z5r5UpUnL40",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.648485994768803\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}